version: '3.1'
services:
    patient-search:
        build:
            context: ./patient-search/
            dockerfile: Dockerfile
        image: hbd-demo-patient-search:latest
        container_name: hbd-demo-patient-search
        volumes:
            - ./patient-search/:/workspace/
            - ./backend/data/checkpoints/:/models/
        environment:
            - PYTHONUNBUFFERED=1
        ports:
            - 51125:5003
        extra_hosts:
            - "host.docker.internal:host-gateway"
        restart: always
    llamacpp:
        container_name: llama-server
        image: llama-cpp-python:latest
        build:
            context: ./llama-server/
            dockerfile: Dockerfile
        volumes:
            - ~/models/:/models/
        ports:
            - 51124:8000
        command: sh -c "python3 -m llama_cpp.server --model /models/mistral-7b-openorca.Q5_K_M.gguf --n_ctx 8000 --chat_format chatml --n_threads 25 --n_gpu_layers 43 --n_batch 200"
        environment:
            - HOST=0.0.0.0
        deploy:
            resources:
                limits:
                    memory: 32GB
                reservations:
                    devices:
                        - driver: nvidia
                          device_ids: [ '1' ]
                          capabilities: [ gpu ]
    frontend:
        image: hbd-demo-frontend:latest
        build:
            context: ./frontend/
            dockerfile: Dockerfile
        volumes:
            - ./frontend/:/usr/src/app/
        # npm install
        container_name: hbd-demo-frontend
        ports:
            - 51118:8080
        restart: always
        command: sh -c "npm install && npm audit fix --force && quasar dev"
    backend:
        build:
            context: ./backend/
            dockerfile: Dockerfile
        image: hbd-demo-backend:latest
        container_name: hbd-demo-backend
        volumes:
            - ./backend/:/workspace/
            - ~/models/:/models/
        environment:
            - PYTHONUNBUFFERED=1
        ports:
            - 51119:5003
        extra_hosts:
            - "host.docker.internal:host-gateway"
        restart: always
        deploy:
            resources:
                limits:
                    memory: 20GB
                reservations:
                    devices:
                        - driver: nvidia
                          device_ids: [ '0' ]
                          capabilities: [ gpu ]
